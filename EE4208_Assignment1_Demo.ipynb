{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "written-notification",
   "metadata": {},
   "source": [
    "# Capture faces via webcam\n",
    "\n",
    "## Instructions to use:\n",
    "\n",
    "1. Run the cell.\n",
    "2. Input name in lower case without spacing. If spacing is required, use underscore instead.\n",
    "3. Take these 5 face expressions:\n",
    "        - No glasses, no smile.\n",
    "        - No glasses, smile, no show teeth.\n",
    "        - No glasses, smile, show teeth.\n",
    "        - Wear glasses, no smile.\n",
    "        - Wear glasses, smile, show teeth.\n",
    "4. Position face in front of webcam so that \"FACE\" and \"EYES\" are detected. Then press \"spacebar\" to capture face image.\n",
    "5. Repeat step 3 for other face expressions.\n",
    "6. Press \"ESC\" to capture different person face.\n",
    "7. Colored face images with roi will be saved in \"ROI_Faces\" folder.\n",
    "8. Grayscale face images without roi, with size (100,100) will be saved in \"Grayscale_Faces\" folder for training the face recognizer.\n",
    "9. Colored face images without roi, with size (224,224) will be saved in \"Color_Faces\" folder for training the face recognizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ongoing-kruger",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-07c13c7a51f3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0meyes_glasses_detector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCascadeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'haarcascade_eye_tree_eyeglasses.xml'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m# For each person, enter one numeric face id\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0muser_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n Enter name and press <enter> ==>  '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n Look at camera and press <spacebar> to take picture\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;31m# Initialize individual sampling face count\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\python36_vggface\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m    861\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    862\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 863\u001b[1;33m             \u001b[0mpassword\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    864\u001b[0m         )\n\u001b[0;32m    865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\python36_vggface\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m    902\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    903\u001b[0m                 \u001b[1;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 904\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Interrupted by user\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    905\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    906\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid Message:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Take face shots via webcam to create face database\n",
    "cam = cv2.VideoCapture(0)\n",
    "cam.set(3, 1280) # set video width\n",
    "cam.set(4, 960) # set video height\n",
    "face_detector = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "eyes_detector = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    "eyes_glasses_detector = cv2.CascadeClassifier('haarcascade_eye_tree_eyeglasses.xml')\n",
    "# For each person, enter one numeric face id\n",
    "user_name = input('\\n Enter name and press <enter> ==>  ')\n",
    "print(\"\\n Look at camera and press <spacebar> to take picture\")\n",
    "# Initialize individual sampling face count\n",
    "count = 1\n",
    "while(True):\n",
    "    ret, img = cam.read()\n",
    "    img = cv2.flip(img, 1) # flip video image vertically\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_detector.detectMultiScale(gray, scaleFactor=1.2, minNeighbors=5, minSize=(5,5))\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img, (x,y), (x+w,y+h), (255,0,0), 2)\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = img[y:y+h, x:x+w]\n",
    "        resized_color = cv2.resize(img[y:y+h,x:x+w], dsize=(224,224), interpolation=cv2.INTER_AREA)\n",
    "        eyes = eyes_glasses_detector.detectMultiScale(roi_gray, scaleFactor=1.2, minNeighbors=5, minSize=(5,5));\n",
    "        for (ex, ey, ew, eh) in eyes:\n",
    "            cv2.rectangle(roi_color, (ex, ey), (ex + ew, ey + eh), (0, 255, 0), 2)\n",
    "            #cv2.rectangle(roi_gray, (ex, ey), (ex + ew, ey + eh), (0, 255, 0), 2)\n",
    "        resized_gray = cv2.resize(gray[y:y+h,x:x+w], dsize=(100,100), interpolation=cv2.INTER_AREA)\n",
    "        \n",
    "    k = cv2.waitKey(1) & 0xff # Press 'ESC' for exiting video\n",
    "    if k == 27:\n",
    "        break\n",
    "    elif k == 32: #if spacebar is pressed\n",
    "        # Save the captured image into the datasets folder\n",
    "        cv2.imwrite(\"ROI_Faces/User.\" + str(user_name).lower() + \".\" + str(count) + \".jpg\", roi_color)\n",
    "        cv2.imwrite(\"Grayscale_Faces/User.\" + str(user_name).lower() + '.'+ str(count) + \".jpg\", resized_gray)\n",
    "        cv2.imwrite(\"Color_Faces/User.\" + str(user_name).lower() + '.' + str(count) + \".jpg\", resized_color)\n",
    "        print(\"Shot {} is taken!\".format(count))\n",
    "        count += 1  \n",
    "    cv2.imshow('image', img)\n",
    "\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liberal-liberal",
   "metadata": {},
   "source": [
    "# Load Face Images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efficient-techno",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_faces_labels(resized_images_path='Resized_Faces'):\n",
    "    file_path = os.listdir(resized_images_path)\n",
    "    faces = []\n",
    "    face_labels = []\n",
    "    current_id=0\n",
    "    label_ids={}\n",
    "    for file in file_path:\n",
    "        if file.endswith(\"png\") or file.endswith(\"jpg\"):\n",
    "            path=os.path.join(resized_images_path, file)\n",
    "            label=os.path.basename(path).split(\".\")[1]\n",
    "            #print(label,path)\n",
    "            if not label in label_ids:\n",
    "                #label_ids[label] = os.path.basename(path).split(\".\")[2]\n",
    "                label_ids[label]=current_id\n",
    "                current_id+=1\n",
    "\n",
    "            id_=label_ids[label]\n",
    "            pil_image=Image.open(path)#grayscale\n",
    "            image_array=np.array(pil_image,'uint8')\n",
    "                           \n",
    "            #print(image_array)\n",
    "            faces.append(image_array)\n",
    "            face_labels.append(id_)\n",
    "            faces_array = np.array(faces)\n",
    "            labels_array = np.array(face_labels)\n",
    "    return faces_array, labels_array, label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "threatened-billy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Training Faces:  (100, 100, 100)\n",
      "########################################\n",
      "Shape of Face Labels:  (100,)\n",
      "########################################\n",
      "Dictionary of Person Name and Label:  {'bryan_lee': 0, 'bryan_lim': 1, 'chin_fung': 2, 'darren': 3, 'edmund': 4, 'john': 5, 'lam': 6, 'malvern': 7, 'meinv': 8, 'nicholas': 9, 'peter': 10, 'terren': 11, 'wangjue': 12, 'yicheng': 13, 'yirong': 14, 'yongzhe': 15, 'yuanjun': 16, 'zhijia': 17, 'zihang': 18, 'ziying': 19}\n",
      "########################################\n",
      "Labels:  [ 0  0  0  0  0  1  1  1  1  1  2  2  2  2  2  3  3  3  3  3  4  4  4  4\n",
      "  4  5  5  5  5  5  6  6  6  6  6  7  7  7  7  7  8  8  8  8  8  9  9  9\n",
      "  9  9 10 10 10 10 10 11 11 11 11 11 12 12 12 12 12 13 13 13 13 13 14 14\n",
      " 14 14 14 15 15 15 15 15 16 16 16 16 16 17 17 17 17 17 18 18 18 18 18 19\n",
      " 19 19 19 19]\n"
     ]
    }
   ],
   "source": [
    "# Load labelled face datasets\n",
    "face, labels, name_label_dict = get_faces_labels()\n",
    "print(\"Shape of Training Faces: \",face.shape)\n",
    "print(\"########################################\")\n",
    "print(\"Shape of Face Labels: \",labels.shape)\n",
    "print(\"########################################\")\n",
    "print(\"Dictionary of Person Name and Label: \",name_label_dict)\n",
    "print(\"########################################\")\n",
    "print(\"Labels: \",labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sporting-amber",
   "metadata": {},
   "source": [
    "# Train LBPH Face Recognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "listed-balance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train face recognizer and save trained recognizer.\n",
    "face_recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "face_recognizer.train(face, labels)\n",
    "face_recognizer.save(\"LBPH_Face_Recognizer.yml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mexican-aspect",
   "metadata": {},
   "source": [
    "# Real-Time Face Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "rolled-valentine",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lbph_face_recognition():\n",
    "    faceCascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml') # load classifier\n",
    "    eyeCascade = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    "    eye_glassesCascade = cv2.CascadeClassifier('haarcascade_eye_tree_eyeglasses.xml')\n",
    "    smileCascade = cv2.CascadeClassifier('haarcascade_smile.xml')\n",
    "    #faceCascade = cv2.CascadeClassifier('lbpcascade_frontalface.xml') # load classifier\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    #face_recognizer = cv2.face.EigenFaceRecognizer_create()\n",
    "    face_recognizer=cv2.face.LBPHFaceRecognizer_create()\n",
    "    face_recognizer.read(\"LBPH_Face_Recognizer.yml\")\n",
    "\n",
    "    #Load face labels\n",
    "    # with open('face_eye_smile_labels.pickle', 'rb') as f:\n",
    "    #     y_train = np.array(pickle.load(f))\n",
    "    names = ['Bryan_Lee', 'Bryan_Lim', 'Chin_Fung', 'Darren', 'Edmund', 'John', 'Lam', \n",
    "             'Malvern', 'meinv', 'Nicholas', 'Peter', 'Ter_Ren', 'Wang_Jue', 'Yi_Cheng', \n",
    "             'Yi_Rong', 'Yong_Zhe', 'Yuan_Jun', 'Zhi_jia', 'Zi_Hang', 'Zi_Ying']\n",
    "    \n",
    "    cap.set(3,640) # set Width\n",
    "    cap.set(4,480) # set Height\n",
    "    while True:\n",
    "        _, frame = cap.read()\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # detect faces\n",
    "        faces = faceCascade.detectMultiScale(\n",
    "            gray,     \n",
    "            scaleFactor=1.2,\n",
    "            minNeighbors=5,     \n",
    "            minSize=(5, 5)\n",
    "        )\n",
    "        found=0\n",
    "        for (x,y,w,h) in faces:\n",
    "            cv2.rectangle(frame,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "            roi_color = frame[y:y+h, x:x+w]\n",
    "            roi_gray = gray[y:y+h, x:x+w]\n",
    "    #        roi_gray = cv2.resize(roi_gray, (100,100))\n",
    "            eyes = eye_glassesCascade.detectMultiScale(roi_gray, scaleFactor=1.2, minNeighbors=5, minSize=(5,5))\n",
    "            for (ex, ey, ew, eh) in eyes:\n",
    "                cv2.rectangle(roi_color, (ex, ey), (ex + ew, ey + eh), (0, 255, 0), 2)\n",
    "    #         smile = smileCascade.detectMultiScale(roi_gray, scaleFactor=1.2, minNeighbors=25, minSize=(120,120))\n",
    "    #         for (xx, yy, ww, hh) in smile:\n",
    "    #             cv2.rectangle(roi_color, (xx, yy), (xx + ww, yy + hh), (0, 0, 255), 2)\n",
    "            gray_face = cv2.resize((gray[y:y+h,x:x+w]),(100,100))\n",
    "            label, conf = face_recognizer.predict(gray_face)\n",
    "            \n",
    "            found=1\n",
    "            \n",
    "        if (found==1):\n",
    "\n",
    "            if conf<=120:\n",
    "                person = names[label]\n",
    "            else:\n",
    "                person = \"Unknown\"\n",
    "\n",
    "            text = str(label) + person + \":\" + str(round(conf,3))\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "            cv2.putText(frame, text, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "\n",
    "        elif (found==0):\n",
    "            eyes = eye_glassesCascade.detectMultiScale(gray, scaleFactor=1.2, minNeighbors=5, minSize=(5,5))\n",
    "            for (ex, ey, ew, eh) in eyes:\n",
    "                roi_gray = gray[ey:ey+eh, ex:ex+ew]\n",
    "                cv2.rectangle(frame, (ex, ey), (ex + ew, ey + eh), (0, 255, 0), 2)\n",
    "        #         smile = smileCascade.detectMultiScale(roi_gray, scaleFactor=1.2, minNeighbors=25, minSize=(120,120))\n",
    "        #         for (xx, yy, ww, hh) in smile:\n",
    "        #             cv2.rectangle(roi_color, (xx, yy), (xx + ww, yy + hh), (0, 0, 255), 2)\n",
    "            #gray_eyes = cv2.resize((gray[y:y+h,x:x+w]),(100,100))\n",
    "                label, conf = face_recognizer.predict(gray)\n",
    "            if conf<=120:\n",
    "                person = names[label]\n",
    "\n",
    "            else:\n",
    "                person = \"Unknown\"\n",
    "\n",
    "            text = str(label) + person + \":\" + str(round(conf,3))\n",
    "            cv2.rectangle(frame, (ex, ey), (ex + ew, ey + eh), (255, 0, 0), 2)\n",
    "            cv2.putText(frame, text, (ex, ey - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "\n",
    "        cv2.imshow('frame',frame)\n",
    "        k = cv2.waitKey(1) & 0xff\n",
    "        if k == 27: # press 'ESC' to quit\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acknowledged-decline",
   "metadata": {},
   "outputs": [],
   "source": [
    "lbph_face_recognition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arbitrary-raising",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
