{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "written-notification",
   "metadata": {},
   "source": [
    "# Capture faces via webcam\n",
    "\n",
    "## Instructions to use:\n",
    "\n",
    "1. Run the cell.\n",
    "2. Input name in lower case without spacing. If spacing is required, use underscore instead.\n",
    "3. Take these 5 face expressions:\n",
    "        - No glasses, no smile.\n",
    "        - No glasses, smile, no show teeth.\n",
    "        - No glasses, smile, show teeth.\n",
    "        - Wear glasses, no smile.\n",
    "        - Wear glasses, smile, show teeth.\n",
    "4. Position face in front of webcam so that \"FACE\" and \"EYES\" are detected. Then press \"spacebar\" to capture face image.\n",
    "5. Repeat step 3 for other face expressions.\n",
    "6. Press \"ESC\" to capture different person face.\n",
    "7. Colored face images with roi will be saved in \"ROI_Faces\" folder.\n",
    "8. Grayscale face images without roi, with size (100,100) will be saved in \"Grayscale_Faces\" folder for training the face recognizer.\n",
    "9. Colored face images without roi, with size (224,224) will be saved in \"Color_Faces\" folder for training the face recognizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ongoing-kruger",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Enter name and press <enter> ==>  yirong\n",
      "\n",
      " Look at camera and press <spacebar> to take picture\n",
      "Shot 1 is taken!\n",
      "Shot 2 is taken!\n",
      "Shot 3 is taken!\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Take face shots via webcam to create face database\n",
    "cam = cv2.VideoCapture(0)\n",
    "cam.set(3, 1280) # set video width\n",
    "cam.set(4, 960) # set video height\n",
    "face_detector = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "eyes_detector = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    "eyes_glasses_detector = cv2.CascadeClassifier('haarcascade_eye_tree_eyeglasses.xml')\n",
    "# For each person, enter name and press spacebar to take picture.\n",
    "user_name = input('\\n Enter name and press <enter> ==>  ')\n",
    "print(\"\\n Look at camera and press <spacebar> to take picture\")\n",
    "# Initialize individual sampling face count\n",
    "count = 1\n",
    "while(True):\n",
    "    ret, img = cam.read()\n",
    "    img = cv2.flip(img, 1) # flip video image vertically\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_detector.detectMultiScale(gray, scaleFactor=1.2, minNeighbors=5, minSize=(5,5))\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img, (x,y), (x+w,y+h), (255,0,0), 2)\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = img[y:y+h, x:x+w]\n",
    "        resized_color = cv2.resize(img[y:y+h,x:x+w], dsize=(224,224), interpolation=cv2.INTER_AREA)\n",
    "        eyes = eyes_glasses_detector.detectMultiScale(roi_gray, scaleFactor=1.2, minNeighbors=5, minSize=(5,5));\n",
    "        for (ex, ey, ew, eh) in eyes:\n",
    "            cv2.rectangle(roi_color, (ex, ey), (ex + ew, ey + eh), (0, 255, 0), 2)\n",
    "            #cv2.rectangle(roi_gray, (ex, ey), (ex + ew, ey + eh), (0, 255, 0), 2)\n",
    "        resized_gray = cv2.resize(gray[y:y+h,x:x+w], dsize=(100,100), interpolation=cv2.INTER_AREA)\n",
    "        \n",
    "    k = cv2.waitKey(1) & 0xff # Press 'ESC' for exiting video\n",
    "    if k == 27:\n",
    "        break\n",
    "    elif k == 32: #if spacebar is pressed\n",
    "        # Save the captured image into the datasets folder\n",
    "        cv2.imwrite(\"ROI_Faces/User.\" + str(user_name).lower() + \".\" + str(count) + \".jpg\", roi_color)\n",
    "        cv2.imwrite(\"Grayscale_Faces/User.\" + str(user_name).lower() + '.'+ str(count) + \".jpg\", resized_gray)\n",
    "        cv2.imwrite(\"Color_Faces/User.\" + str(user_name).lower() + '.' + str(count) + \".jpg\", resized_color)\n",
    "        print(\"Shot {} is taken!\".format(count))\n",
    "        count += 1  \n",
    "    cv2.imshow('image', img)\n",
    "\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liberal-liberal",
   "metadata": {},
   "source": [
    "# Load Face Images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "efficient-techno",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_faces_labels(resized_images_path='Resized_Faces'):\n",
    "    file_path = os.listdir(resized_images_path)\n",
    "    faces = []\n",
    "    face_labels = []\n",
    "    current_id=0\n",
    "    label_ids={}\n",
    "    for file in file_path:\n",
    "        if file.endswith(\"png\") or file.endswith(\"jpg\"):\n",
    "            path=os.path.join(resized_images_path, file)\n",
    "            label=os.path.basename(path).split(\".\")[1]\n",
    "            #print(label,path)\n",
    "            if not label in label_ids:\n",
    "                #label_ids[label] = os.path.basename(path).split(\".\")[2]\n",
    "                label_ids[label]=current_id\n",
    "                current_id+=1\n",
    "\n",
    "            id_=label_ids[label]\n",
    "            pil_image=Image.open(path)#grayscale\n",
    "            image_array=np.array(pil_image,'uint8')\n",
    "                           \n",
    "            #print(image_array)\n",
    "            faces.append(image_array)\n",
    "            face_labels.append(id_)\n",
    "            faces_array = np.array(faces)\n",
    "            labels_array = np.array(face_labels)\n",
    "    return faces_array, labels_array, label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "threatened-billy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Training Faces:  (100, 100, 100)\n",
      "########################################\n",
      "Shape of Face Labels:  (100,)\n",
      "########################################\n",
      "Dictionary of Person Name and Label:  {'bryan_lee': 0, 'bryan_lim': 1, 'chin_fung': 2, 'darren': 3, 'edmund': 4, 'john': 5, 'lam': 6, 'malvern': 7, 'meinv': 8, 'nicholas': 9, 'peter': 10, 'terren': 11, 'wangjue': 12, 'yicheng': 13, 'yirong': 14, 'yongzhe': 15, 'yuanjun': 16, 'zhijia': 17, 'zihang': 18, 'ziying': 19}\n",
      "########################################\n",
      "Labels:  [ 0  0  0  0  0  1  1  1  1  1  2  2  2  2  2  3  3  3  3  3  4  4  4  4\n",
      "  4  5  5  5  5  5  6  6  6  6  6  7  7  7  7  7  8  8  8  8  8  9  9  9\n",
      "  9  9 10 10 10 10 10 11 11 11 11 11 12 12 12 12 12 13 13 13 13 13 14 14\n",
      " 14 14 14 15 15 15 15 15 16 16 16 16 16 17 17 17 17 17 18 18 18 18 18 19\n",
      " 19 19 19 19]\n"
     ]
    }
   ],
   "source": [
    "# Load labelled face datasets\n",
    "face, labels, name_label_dict = get_faces_labels()\n",
    "print(\"Shape of Training Faces: \",face.shape)\n",
    "print(\"########################################\")\n",
    "print(\"Shape of Face Labels: \",labels.shape)\n",
    "print(\"########################################\")\n",
    "print(\"Dictionary of Person Name and Label: \",name_label_dict)\n",
    "print(\"########################################\")\n",
    "print(\"Labels: \",labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sporting-amber",
   "metadata": {},
   "source": [
    "# Train LBPH Face Recognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "listed-balance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train face recognizer and save trained recognizer.\n",
    "face_recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "face_recognizer.train(face, labels)\n",
    "face_recognizer.save(\"LBPH_Face_Recognizer.yml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mexican-aspect",
   "metadata": {},
   "source": [
    "# Real-Time Face Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "collaborative-shopping",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "seven-mason",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lbph_face_recognition():\n",
    "    faceCascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml') # load classifier\n",
    "    eyeCascade = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    "    eye_glassesCascade = cv2.CascadeClassifier('haarcascade_eye_tree_eyeglasses.xml')\n",
    "    smileCascade = cv2.CascadeClassifier('haarcascade_smile.xml')\n",
    "    #faceCascade = cv2.CascadeClassifier('lbpcascade_frontalface.xml') # load classifier\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    #face_recognizer = cv2.face.EigenFaceRecognizer_create()\n",
    "    face_recognizer=cv2.face.LBPHFaceRecognizer_create()\n",
    "    face_recognizer.read(\"LBPH_Face_Recognizer.yml\")\n",
    "\n",
    "    #Load face labels\n",
    "    # with open('face_eye_smile_labels.pickle', 'rb') as f:\n",
    "    #     y_train = np.array(pickle.load(f))\n",
    "    names = ['Bryan_Lee', 'Bryan_Lim', 'Chin_Fung', 'Darren', 'Edmund', 'John', 'Lam', \n",
    "             'Malvern', 'meinv', 'Nicholas', 'Peter', 'Ter_Ren', 'Wang_Jue', 'Yi_Cheng', \n",
    "             'Yi_Rong', 'Yong_Zhe', 'Yuan_Jun', 'Zhi_jia', 'Zi_Hang', 'Zi_Ying']\n",
    "    \n",
    "    cap.set(3,1280) # set Width\n",
    "    cap.set(4,960) # set Height\n",
    "    while True:\n",
    "        _, frame = cap.read()\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # detect faces\n",
    "        faces = faceCascade.detectMultiScale(\n",
    "            gray,     \n",
    "            scaleFactor=1.2,\n",
    "            minNeighbors=5,     \n",
    "            minSize=(5, 5)\n",
    "        )\n",
    "        \n",
    "        for (x,y,w,h) in faces:\n",
    "            cv2.rectangle(frame,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "            roi_color = frame[y:y+h, x:x+w]\n",
    "            roi_gray = gray[y:y+h, x:x+w]\n",
    "    #        roi_gray = cv2.resize(roi_gray, (100,100))\n",
    "            eyes = eye_glassesCascade.detectMultiScale(roi_gray, scaleFactor=1.2, minNeighbors=5, minSize=(5,5))\n",
    "            for (ex, ey, ew, eh) in eyes:\n",
    "                cv2.rectangle(roi_color, (ex, ey), (ex + ew, ey + eh), (0, 255, 0), 2)\n",
    "    #         smile = smileCascade.detectMultiScale(roi_gray, scaleFactor=1.2, minNeighbors=25, minSize=(120,120))\n",
    "    #         for (xx, yy, ww, hh) in smile:\n",
    "    #             cv2.rectangle(roi_color, (xx, yy), (xx + ww, yy + hh), (0, 0, 255), 2)\n",
    "            gray_face = cv2.resize((gray[y:y+h,x:x+w]),(100,100))\n",
    "            label, conf = face_recognizer.predict(gray_face)\n",
    "\n",
    "            if conf<=110:\n",
    "                person = names[label]\n",
    "            else:\n",
    "                person = \"Unknown\"\n",
    "\n",
    "            text = str(label) + person + \":\" + str(round(conf,3))\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "            cv2.putText(frame, text, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "\n",
    "        \n",
    "        \n",
    "            print(person, round(conf,1))\n",
    "        cv2.imshow('frame',frame)\n",
    "        k = cv2.waitKey(1) & 0xff\n",
    "        if k == 27: # press 'ESC' to quit\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "acknowledged-decline",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yi_Rong 101.7\n",
      "Wang_Jue 103.9\n",
      "Wang_Jue 106.9\n",
      "Unknown 132.7\n",
      "Wang_Jue 107.5\n",
      "Unknown 110.4\n",
      "Wang_Jue 107.4\n",
      "Wang_Jue 107.5\n",
      "Yi_Rong 107.1\n",
      "Wang_Jue 108.4\n",
      "Wang_Jue 107.7\n",
      "Yi_Rong 108.8\n",
      "Yi_Rong 109.0\n",
      "Yi_Rong 108.8\n",
      "Wang_Jue 107.4\n",
      "Yi_Rong 109.7\n",
      "Yi_Rong 109.0\n",
      "Yi_Rong 106.5\n",
      "Yi_Rong 107.0\n",
      "Yi_Rong 106.2\n",
      "Yi_Rong 107.1\n",
      "Yi_Rong 107.0\n",
      "Yi_Rong 108.7\n",
      "Yi_Rong 107.9\n",
      "Yi_Rong 108.6\n",
      "Yi_Rong 107.9\n",
      "Yi_Rong 107.0\n",
      "Yi_Rong 106.6\n",
      "Yi_Rong 107.7\n",
      "Yi_Rong 105.7\n",
      "Yi_Rong 106.3\n",
      "Yi_Rong 108.5\n",
      "Yi_Rong 107.7\n",
      "Yi_Rong 107.1\n",
      "Unknown 110.1\n",
      "Unknown 131.4\n",
      "Unknown 128.5\n",
      "Unknown 129.0\n",
      "Wang_Jue 105.6\n",
      "Yi_Rong 107.1\n",
      "Wang_Jue 106.5\n",
      "Yi_Cheng 102.5\n",
      "Yi_Cheng 104.6\n",
      "Yi_Cheng 101.1\n",
      "Wang_Jue 100.9\n",
      "Wang_Jue 101.9\n",
      "Wang_Jue 102.4\n",
      "Wang_Jue 103.4\n",
      "Yi_Cheng 99.3\n",
      "Yi_Cheng 98.8\n",
      "Yi_Cheng 99.6\n",
      "Wang_Jue 103.8\n",
      "Wang_Jue 104.7\n",
      "Wang_Jue 102.7\n",
      "Wang_Jue 104.7\n",
      "Wang_Jue 102.9\n",
      "Wang_Jue 103.0\n",
      "Wang_Jue 101.7\n",
      "Wang_Jue 102.9\n",
      "Yi_Cheng 101.6\n",
      "Wang_Jue 102.2\n",
      "Yi_Cheng 99.7\n",
      "Yi_Cheng 101.9\n",
      "Wang_Jue 99.6\n",
      "Wang_Jue 101.6\n",
      "Yi_Cheng 99.9\n",
      "Yi_Cheng 102.3\n",
      "Yi_Cheng 103.9\n",
      "Wang_Jue 103.8\n",
      "Wang_Jue 102.0\n",
      "Unknown 118.9\n",
      "Unknown 115.2\n",
      "Unknown 113.6\n",
      "Zi_Ying 106.0\n",
      "Yi_Rong 102.1\n",
      "Zi_Ying 95.9\n",
      "Malvern 96.5\n",
      "Malvern 96.4\n",
      "Malvern 94.0\n",
      "Malvern 94.5\n",
      "Unknown 127.5\n",
      "Malvern 95.3\n",
      "Malvern 95.1\n",
      "John 95.8\n",
      "Malvern 94.0\n",
      "John 95.3\n",
      "Malvern 93.1\n",
      "Malvern 94.8\n",
      "Malvern 94.2\n",
      "Malvern 95.0\n",
      "Unknown 124.6\n",
      "Malvern 94.1\n",
      "Malvern 95.9\n",
      "Unknown 127.2\n",
      "Malvern 93.5\n",
      "Malvern 93.2\n",
      "Malvern 93.4\n",
      "Malvern 95.7\n",
      "Malvern 94.9\n",
      "Malvern 95.4\n",
      "Malvern 96.2\n",
      "Unknown 127.1\n",
      "Malvern 94.3\n",
      "Malvern 97.1\n",
      "Malvern 93.7\n",
      "John 96.1\n",
      "Unknown 128.4\n",
      "John 96.9\n",
      "Malvern 95.6\n",
      "Unknown 125.3\n",
      "Malvern 97.0\n",
      "Unknown 123.5\n",
      "Unknown 126.3\n",
      "Malvern 99.5\n",
      "Zi_Ying 108.1\n",
      "Wang_Jue 109.8\n",
      "Unknown 123.1\n",
      "Unknown 123.5\n",
      "Unknown 116.6\n",
      "Unknown 113.3\n",
      "Unknown 111.2\n",
      "John 102.1\n",
      "Edmund 99.4\n",
      "Bryan_Lee 102.0\n",
      "Edmund 100.9\n",
      "John 103.6\n",
      "Bryan_Lim 102.0\n",
      "Edmund 96.4\n",
      "Bryan_Lim 97.8\n",
      "Unknown 129.9\n",
      "John 96.4\n",
      "Unknown 128.1\n",
      "Bryan_Lim 97.7\n",
      "Unknown 124.5\n",
      "Bryan_Lim 99.4\n",
      "Unknown 130.3\n",
      "John 98.5\n",
      "Bryan_Lim 99.1\n",
      "Unknown 129.0\n",
      "John 98.4\n",
      "Unknown 128.5\n",
      "Unknown 127.8\n",
      "John 101.9\n",
      "John 98.5\n",
      "Unknown 124.3\n",
      "John 95.7\n",
      "Bryan_Lim 101.0\n",
      "Unknown 127.4\n",
      "John 99.0\n",
      "John 98.0\n",
      "Unknown 122.3\n",
      "John 99.0\n",
      "Bryan_Lim 98.2\n",
      "Bryan_Lim 98.7\n",
      "Unknown 125.0\n",
      "Edmund 98.4\n",
      "Unknown 122.9\n",
      "Bryan_Lim 99.6\n",
      "Bryan_Lim 97.0\n",
      "Unknown 125.7\n",
      "Bryan_Lim 100.5\n",
      "Unknown 124.6\n",
      "Bryan_Lim 98.7\n",
      "Bryan_Lim 101.7\n",
      "Unknown 120.4\n",
      "John 98.1\n",
      "Unknown 127.7\n",
      "John 103.3\n",
      "Unknown 123.8\n",
      "Bryan_Lim 99.4\n",
      "Edmund 99.4\n",
      "John 101.3\n",
      "Edmund 98.4\n",
      "Unknown 123.8\n",
      "Edmund 100.4\n",
      "Unknown 120.0\n",
      "John 99.9\n",
      "John 98.5\n",
      "Bryan_Lim 99.1\n",
      "Unknown 128.4\n",
      "John 99.0\n",
      "Bryan_Lim 97.4\n",
      "John 97.7\n",
      "John 98.1\n",
      "John 100.1\n",
      "Bryan_Lim 101.4\n",
      "Bryan_Lim 95.7\n",
      "Bryan_Lim 100.0\n",
      "Bryan_Lim 94.7\n",
      "Bryan_Lim 96.4\n",
      "Bryan_Lim 95.6\n",
      "Bryan_Lim 93.8\n",
      "Bryan_Lim 95.4\n",
      "Bryan_Lim 96.0\n",
      "Bryan_Lim 93.8\n",
      "Bryan_Lim 95.6\n",
      "Unknown 120.2\n",
      "Bryan_Lim 96.5\n",
      "Bryan_Lim 96.8\n",
      "Edmund 95.3\n",
      "Bryan_Lim 94.9\n",
      "Bryan_Lim 95.5\n",
      "John 96.6\n",
      "Bryan_Lim 97.6\n",
      "Bryan_Lim 94.0\n",
      "John 94.1\n",
      "Bryan_Lim 95.8\n",
      "Bryan_Lim 93.2\n",
      "John 94.7\n",
      "Bryan_Lim 95.5\n",
      "Bryan_Lim 95.8\n",
      "Bryan_Lim 95.9\n",
      "John 96.0\n",
      "Bryan_Lim 96.5\n",
      "John 95.0\n",
      "Bryan_Lim 96.5\n",
      "John 92.3\n",
      "Bryan_Lim 94.8\n",
      "John 97.4\n",
      "John 96.8\n",
      "Bryan_Lim 96.5\n",
      "Bryan_Lim 96.8\n",
      "Bryan_Lim 97.3\n",
      "John 96.8\n",
      "Bryan_Lim 96.6\n",
      "John 98.4\n",
      "John 98.1\n",
      "Bryan_Lim 97.6\n",
      "John 95.9\n",
      "John 96.9\n",
      "Bryan_Lim 97.3\n",
      "Bryan_Lim 96.2\n",
      "Bryan_Lim 95.5\n",
      "John 98.8\n",
      "John 97.0\n",
      "Unknown 118.6\n",
      "Unknown 121.1\n",
      "Unknown 119.2\n",
      "Unknown 123.5\n"
     ]
    }
   ],
   "source": [
    "lbph_face_recognition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arbitrary-raising",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
