{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions to use face_functions.py\n",
    "\n",
    "## This python file contains several functions which can be called by:\n",
    "\n",
    "    1. import face_functions\n",
    "    2. Use any function in here by calling face_functions.function-name(args) at another IDE.\n",
    "   \n",
    "## List of Functions Available:\n",
    "\n",
    "    1. get_faces_labels(image_path): return arrays of 100x100 grayscale faces, labels, and dictionary {name:label}\n",
    "    2. get_faces_labels_pca(image_path): return arrays of 1D grayscale faces, labels, and dictionary {name:label}\n",
    "    3. normalise_face(face_array, n, m): return average face (1,10000), zeromean face (n,10000), eigenvalues (1,m), eigenvectors (10000,m), eigenfaces (m,10000), pca faces (n,m), covariance matrix (10000,10000)\n",
    "    4. normalise_test_face(test_face_array, avg_face, eigenvectors): return zeromean test face(1,10000), pca test face (1,m). \n",
    "    5. plot_gallery(): return plots of eigenfaces. \n",
    "    6. face_recognition(): real time face recognition without mask.\n",
    "    7. face_mask_recognition(): real time face recognition with mask.\n",
    "    8. pca_face_recognition(): real time pca face recognition without mask using SVM.\n",
    "    9. to_rgb(image): return grayscale image.\n",
    "    10. face_detection(cascade, color_img, scaleFactor): return grayscale image and color face roi. \n",
    "    11. face_eyes_detection(cascade1, cascade2, color_img, scaleFactor): return grayscale image and color face roi. \n",
    "    12. face_eyes_smile_detection(cascade1, cascade2, cascade3, color_img, scaleFactor): return same as above.\n",
    "    13. illumination_normalize(array1d): return grayscale face array (n,10000), bgr face array (n,100,100), ycrcb face array (n, 100, 100).\n",
    "    14. dimension_reduction(face_encoding, n, m): return eigenvalues, eigenvector (2622,m), eigenface, face_train (n,m), covariance matrix.\n",
    "    15. findCosineSimilarity(source, test): return scalar value ranges between 0 and 1.\n",
    "    16. vgg_face_recognition(name_array, face_train, eigenvector): real time face recogniton using Euclidean Distance.\n",
    "\n",
    "**Note: In normalise_face(), change the m value according for different top m features.**\n",
    "\n",
    "**Note: In plot_gallery(), Change the n_row and n_col accordingly. n_row * n_col should be equal to the m value.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import os, sys\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from scipy import linalg\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 Get Face Images and Face Labels from Resized_Faces for Face Training\n",
    "def get_faces_labels(resized_images_path='Resized_Faces'):\n",
    "    file_path = os.listdir(resized_images_path)\n",
    "    faces = []\n",
    "    face_labels = []\n",
    "    current_id=0\n",
    "    label_ids={}\n",
    "    for file in file_path:\n",
    "        if file.endswith(\"png\") or file.endswith(\"jpg\"):\n",
    "            path=os.path.join(resized_images_path, file)\n",
    "            label=os.path.basename(path).split(\".\")[1]\n",
    "            #print(label,path)\n",
    "            if not label in label_ids:\n",
    "                #label_ids[label] = os.path.basename(path).split(\".\")[2]\n",
    "                label_ids[label]=current_id\n",
    "                current_id+=1\n",
    "\n",
    "            id_=label_ids[label]\n",
    "            pil_image=Image.open(path)#grayscale\n",
    "            image_array=np.array(pil_image,'uint8')\n",
    "                           \n",
    "            #print(image_array)\n",
    "            faces.append(image_array)\n",
    "            face_labels.append(id_)\n",
    "            faces_array = np.array(faces)\n",
    "            labels_array = np.array(face_labels)\n",
    "    return faces_array, labels_array, label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 Get Face Images and Face Labels from Resized_Faces for PCA Training\n",
    "def get_faces_labels_pca(resized_images_path='Resized_Faces'):\n",
    "    file_path = os.listdir(resized_images_path)\n",
    "    faces = []\n",
    "    face_labels = []\n",
    "    current_id=0\n",
    "    label_ids={}\n",
    "    for file in file_path:\n",
    "        if file.endswith(\"png\") or file.endswith(\"jpg\"):\n",
    "            path=os.path.join(resized_images_path, file)\n",
    "            label=os.path.basename(path).split(\".\")[1]\n",
    "            #print(label,path)\n",
    "            if not label in label_ids:\n",
    "                #label_ids[label] = os.path.basename(path).split(\".\")[2]\n",
    "                label_ids[label]=current_id\n",
    "                current_id+=1\n",
    "\n",
    "            id_=label_ids[label]\n",
    "            pil_image=Image.open(path)#grayscale\n",
    "            image_array=np.array(pil_image,'uint8')\n",
    "            #reshape 2D array into 1D array\n",
    "            image_1d = image_array.reshape(-1)\n",
    "                           \n",
    "            #print(image_array)\n",
    "            faces.append(image_1d)\n",
    "            face_labels.append(id_)\n",
    "            faces_array = np.array(faces)\n",
    "            labels_array = np.array(face_labels)\n",
    "    return faces_array, labels_array, label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 Process training faces for training SVM\n",
    "def normalise_face(image, n=65, m=40):\n",
    "    # Find average face based on face dataset, return shape (50, 10000)\n",
    "    avg_face = np.mean(image, axis=0)\n",
    "    print(\"avg face (1,10000): \", avg_face.shape)\n",
    "    # Compute zero mean faces, return shape (50, 10000)\n",
    "    zeromean_face = image - avg_face\n",
    "    print(\"zero mean face (n,10000): \", zeromean_face.shape)\n",
    "    # Compute covariance matrix, return shape (10000, 10000)\n",
    "    covariance = np.dot(zeromean_face.T, zeromean_face) / n\n",
    "    print(\"covariance matrix shape (10000, 10000): \", covariance.shape)\n",
    "    total_features = image.shape[1] # 10000 features\n",
    "    print(\"Calculaing top eigenvalues and corresponding eigenvectors...\")\n",
    "    # Compute eigenval and eigenvec, return shape (1, m) and (10000, m)\n",
    "    eigenvalues, eigenvectors = linalg.eigh(covariance, eigvals=(total_features-m,total_features-1))\n",
    "    print(\"eigenvalues shape (m,): \", eigenvalues.shape)\n",
    "    print(\"eigenvectors shape (10000, m): \", eigenvectors.shape)\n",
    "    print(\"Eigens Computation Done!\")\n",
    "    # Compute eigenfaces, return shape (m, 10000)\n",
    "    eigenfaces = eigenvectors.T\n",
    "    print(\"eigenface shape (m,10000)\", eigenfaces.shape)\n",
    "    # Project zero mean faces into eigen space for training, return shape (50, m)\n",
    "    face_train = np.dot(zeromean_face, eigenvectors)\n",
    "    print(\"face_train (n,m): \", face_train.shape)\n",
    "    return avg_face, zeromean_face, eigenvalues, eigenvectors, eigenfaces, face_train, covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4 Process real time detection face (per detected face)\n",
    "def normalise_test_face(image, avg_face, eigenvectors):\n",
    "    zeromean_testface = image - avg_face\n",
    "    face_test = np.dot(zeromean_testface, eigenvectors)\n",
    "    return zeromean_testface, face_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5 Plot eigenfaces\n",
    "def plot_gallery(images, titles, h, w, n_row=8, n_col=5):\n",
    "    \"\"\"Helper function to plot a gallery of portraits\"\"\"\n",
    "    plt.figure(figsize=(1.8 * n_col, 2.4 * n_row))\n",
    "    plt.subplots_adjust(bottom=0, left=.01, right=.99, top=.90, hspace=.35)\n",
    "    for i in range(n_row * n_col):\n",
    "        plt.subplot(n_row, n_col, i + 1)\n",
    "        plt.imshow(images[i].reshape((h, w)), cmap=plt.cm.gray)\n",
    "        plt.title(titles[i], size=12)\n",
    "        plt.xticks(())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6 Real-Time Detection using webcam after training the face recognizer\n",
    "def face_recognition():\n",
    "    faceCascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml') # load classifier\n",
    "    eyeCascade = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    "    eye_glassesCascade = cv2.CascadeClassifier('haarcascade_eye_tree_eyeglasses.xml')\n",
    "    smileCascade = cv2.CascadeClassifier('haarcascade_smile.xml')\n",
    "    #faceCascade = cv2.CascadeClassifier('lbpcascade_frontalface.xml') # load classifier\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    #face_recognizer = cv2.face.EigenFaceRecognizer_create()\n",
    "    face_recognizer=cv2.face.LBPHFaceRecognizer_create()\n",
    "    face_recognizer.read(\"LBPH_Face_Recognizer.yml\")\n",
    "\n",
    "    #Load face labels\n",
    "    # with open('face_eye_smile_labels.pickle', 'rb') as f:\n",
    "    #     y_train = np.array(pickle.load(f))\n",
    "    names = ['Bryan_Lee', 'Bryan_Lim', 'Edmund', 'Malvern', 'Ter_Ren', \n",
    "             'Wang_Jue', 'Yi_Cheng', 'Yi_Rong']\n",
    "    cap.set(3,640) # set Width\n",
    "    cap.set(4,480) # set Height\n",
    "    while True:\n",
    "        _, frame = cap.read()\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # detect faces\n",
    "        faces = faceCascade.detectMultiScale(\n",
    "            gray,     \n",
    "            scaleFactor=1.2,\n",
    "            minNeighbors=5,     \n",
    "            minSize=(5, 5)\n",
    "        )\n",
    "        for (x,y,w,h) in faces:\n",
    "            cv2.rectangle(frame,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "            roi_color = frame[y:y+h, x:x+w]\n",
    "            roi_gray = gray[y:y+h, x:x+w]\n",
    "    #        roi_gray = cv2.resize(roi_gray, (100,100))\n",
    "            eyes = eye_glassesCascade.detectMultiScale(roi_gray, scaleFactor=1.2, minNeighbors=5, minSize=(5,5))\n",
    "            for (ex, ey, ew, eh) in eyes:\n",
    "                cv2.rectangle(roi_color, (ex, ey), (ex + ew, ey + eh), (0, 255, 0), 2)\n",
    "    #         smile = smileCascade.detectMultiScale(roi_gray, scaleFactor=1.2, minNeighbors=25, minSize=(120,120))\n",
    "    #         for (xx, yy, ww, hh) in smile:\n",
    "    #             cv2.rectangle(roi_color, (xx, yy), (xx + ww, yy + hh), (0, 0, 255), 2)\n",
    "            gray_face = cv2.resize((gray[y:y+h,x:x+w]),(100,100))\n",
    "            label, conf = face_recognizer.predict(gray_face)\n",
    "\n",
    "            if conf<=110:\n",
    "                person = names[label]\n",
    "            else:\n",
    "                person = \"Unknown\"\n",
    "\n",
    "            text = str(label) + person + \":\" + str(round(conf,3))\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "            cv2.putText(frame, text, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "\n",
    "        cv2.imshow('frame',frame)\n",
    "        k = cv2.waitKey(1) & 0xff\n",
    "        if k == 27: # press 'ESC' to quit\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With mask on\n",
    "#7 Real-Time Detection using webcam after training the face recognizer\n",
    "def face_mask_recognition():\n",
    "    faceCascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml') # load classifier\n",
    "    eyeCascade = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    "    eye_glassesCascade = cv2.CascadeClassifier('haarcascade_eye_tree_eyeglasses.xml')\n",
    "    smileCascade = cv2.CascadeClassifier('haarcascade_smile.xml')\n",
    "    #faceCascade = cv2.CascadeClassifier('lbpcascade_frontalface.xml') # load classifier\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    #face_recognizer = cv2.face.EigenFaceRecognizer_create()\n",
    "    face_recognizer=cv2.face.LBPHFaceRecognizer_create()\n",
    "    face_recognizer.read(\"LBPH_Face_Recognizer.yml\")\n",
    "\n",
    "    #Load face labels\n",
    "    # with open('face_eye_smile_labels.pickle', 'rb') as f:\n",
    "    #     y_train = np.array(pickle.load(f))\n",
    "    names = ['Bryan_Lee', 'Bryan_Lim', 'Edmund', 'Malvern', 'Ter_Ren', \n",
    "             'Wang_Jue', 'Yi_Cheng', 'Yi_Rong']\n",
    "    cap.set(3,640) # set Width\n",
    "    cap.set(4,480) # set Height\n",
    "    while True:\n",
    "        _, frame = cap.read()\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        eyes = eye_glassesCascade.detectMultiScale(gray, scaleFactor=1.2, minNeighbors=5, minSize=(5,5))\n",
    "        for (ex, ey, ew, eh) in eyes:\n",
    "            roi_gray = gray[ey:ey+eh, ex:ex+ew]\n",
    "            cv2.rectangle(frame, (ex, ey), (ex + ew, ey + eh), (0, 255, 0), 2)\n",
    "    #         smile = smileCascade.detectMultiScale(roi_gray, scaleFactor=1.2, minNeighbors=25, minSize=(120,120))\n",
    "    #         for (xx, yy, ww, hh) in smile:\n",
    "    #             cv2.rectangle(roi_color, (xx, yy), (xx + ww, yy + hh), (0, 0, 255), 2)\n",
    "        #gray_eyes = cv2.resize((gray[y:y+h,x:x+w]),(100,100))\n",
    "        label, conf = face_recognizer.predict(gray)\n",
    "\n",
    "        if conf<=145:\n",
    "            person = names[label]\n",
    "\n",
    "        else:\n",
    "            person = \"Unknown\"\n",
    "\n",
    "        text = str(label) + person + \":\" + str(round(conf,3))\n",
    "        cv2.rectangle(frame, (ex, ey), (ex + ew, ey + eh), (255, 0, 0), 2)\n",
    "        cv2.putText(frame, text, (ex, ey - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "\n",
    "        cv2.imshow('frame',frame)\n",
    "        k = cv2.waitKey(1) & 0xff\n",
    "        if k == 27: # press 'ESC' to quit\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#8 Real Time Detection using SVM\n",
    "def pca_face_recognition(avgface, eigenvectors):\n",
    "    faceCascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml') # load classifier\n",
    "    eye_glassesCascade = cv2.CascadeClassifier('haarcascade_eye_tree_eyeglasses.xml')\n",
    "    \n",
    "    # Load trained model\n",
    "    with open('svc_rbf_10_pca.pickle', 'rb') as saved_model:\n",
    "        svc = pickle.load(saved_model)\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    names = ['Bryan_Lee', 'Bryan_Lim', 'Edmund', 'Malvern', 'Mei_nv', 'Peter', 'Ter_Ren', \n",
    "             'Wang_Jue', 'Yi_Cheng', 'Yi_Rong', 'Yong_Zhe', 'Zi_Hang', 'Zi_Ying']\n",
    "    cap.set(3,640) # set Width\n",
    "    cap.set(4,480) # set Height\n",
    "    while True:\n",
    "        _, frame = cap.read()\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # detect faces\n",
    "        faces = faceCascade.detectMultiScale(\n",
    "            gray,     \n",
    "            scaleFactor=1.2,\n",
    "            minNeighbors=5,     \n",
    "            minSize=(5, 5)\n",
    "        )\n",
    "        for (x,y,w,h) in faces:\n",
    "            cv2.rectangle(frame,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "            roi_color = frame[y:y+h, x:x+w]\n",
    "            roi_gray = gray[y:y+h, x:x+w]\n",
    "    #        roi_gray = cv2.resize(roi_gray, (100,100))\n",
    "            eyes = eye_glassesCascade.detectMultiScale(roi_gray, scaleFactor=1.2, minNeighbors=5, minSize=(5,5))\n",
    "            for (ex, ey, ew, eh) in eyes:\n",
    "                cv2.rectangle(roi_color, (ex, ey), (ex + ew, ey + eh), (0, 255, 0), 2)\n",
    "    #         smile = smileCascade.detectMultiScale(roi_gray, scaleFactor=1.2, minNeighbors=25, minSize=(120,120))\n",
    "    #         for (xx, yy, ww, hh) in smile:\n",
    "    #             cv2.rectangle(roi_color, (xx, yy), (xx + ww, yy + hh), (0, 0, 255), 2)\n",
    "            gray_face = cv2.resize((gray[y:y+h,x:x+w]),(100,100))\n",
    "            gray_face_1d = gray_face.reshape(1,-1)\n",
    "            #print(gray_face_1d.shape)\n",
    "            # Process test face the same as trained faces\n",
    "            #train_face, _, _ = get_faces_labels_pca()\n",
    "            #avgface, _, _, eigenface = normalise_face1(train_face)\n",
    "            normface_test, test_face = normalise_test_face1(gray_face_1d, avgface, eigenvectors)\n",
    "            #plt.imshow(normface_test.reshape(100,100), cmap='gray')\n",
    "            y_pred = svc.predict_proba(test_face)\n",
    "            #top_prob = max(y_pred)\n",
    "            top_prob_name = names[np.argmax(y_pred)]\n",
    "            top_prob = y_pred[:,np.argmax(y_pred)]\n",
    "            print(y_pred)\n",
    "            #print(top_prob)\n",
    "            \n",
    "            #text = str(y_pred[0]) + ':' + names[int(y_pred[0])]\n",
    "            text = str(top_prob_name) + \"-Prob: \" + str(top_prob)\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "            cv2.putText(frame, text, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "            \n",
    "        cv2.imshow('frame',frame)\n",
    "        k = cv2.waitKey(1) & 0xff\n",
    "        if k == 27: # press 'ESC' to quit\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#9 To show coloured image using matplotlib, image must be converted to RGB. Default is BGR.\n",
    "def to_rgb(img):\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10\n",
    "def face_detection(cc, color_img, scaleFactor=1.2):\n",
    "    #just making a copy of image passed, so that passed image is not changed\n",
    "    img_copy = color_img.copy()\n",
    "    #convert the color image to gray image as opencv face detector expects gray images\n",
    "    gray_img = cv2.cvtColor(img_copy, cv2.COLOR_BGR2GRAY)       \n",
    "    #let's detect all faces in the image (some faces may be closer to camera than others) images\n",
    "    faces = cc.detectMultiScale(gray_img, scaleFactor=scaleFactor, minNeighbors=5, minSize=(20,20));   \n",
    "    #go over list of faces and draw them as rectangles on original colored img\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(gray_img, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        roi_gray = gray_img[y:y+h, x:x+w]\n",
    "        roi_color = img_copy[y:y+h, x:x+w]\n",
    "\n",
    "    return gray_img, faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#11\n",
    "def face_eyes_detection(cc1, cc2, color_img, scaleFactor=1.2):\n",
    "    #just making a copy of image passed, so that passed image is not changed\n",
    "    img_copy = color_img.copy()\n",
    "    #convert the color image to gray image as opencv face detector expects gray images\n",
    "    gray_img = cv2.cvtColor(img_copy, cv2.COLOR_BGR2GRAY)       \n",
    "    #let's detect all faces in the image (some faces may be closer to camera than others) images\n",
    "    faces = cc1.detectMultiScale(gray_img, scaleFactor=scaleFactor, minNeighbors=5);   \n",
    "    #go over list of faces and draw them as rectangles on original colored img\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(gray_img, (x, y), (x+w, y+h), (0, 255, 0), 5)\n",
    "        roi_gray = gray_img[y:y+h, x:x+w]\n",
    "        roi_color = img_copy[y:y+h, x:x+w]\n",
    "        eyes = cc2.detectMultiScale(roi_gray, scaleFactor=scaleFactor, minNeighbors=5);\n",
    "        for (ex, ey, ew, eh) in eyes:\n",
    "            cv2.rectangle(roi_gray, (ex, ey), (ex + ew, ey + eh), (255, 0, 0), 5)\n",
    "    return gray_img, faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#12\n",
    "def face_eyes_smile_detection(cc1, cc2, cc3, color_img, scaleFactor=1.2):\n",
    "    #just making a copy of image passed, so that passed image is not changed\n",
    "    img_copy = color_img.copy()\n",
    "    #convert the color image to gray image as opencv face detector expects gray images\n",
    "    gray_img = cv2.cvtColor(img_copy, cv2.COLOR_BGR2GRAY)       \n",
    "    #let's detect all faces in the image (some faces may be closer to camera than others) images\n",
    "    faces = cc1.detectMultiScale(gray_img, scaleFactor=scaleFactor, minNeighbors=5);   \n",
    "    #go over list of faces and draw them as rectangles on original colored img\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(gray_img, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "        roi_gray = gray_img[y:y+h, x:x+w]\n",
    "        roi_color = img_copy[y:y+h, x:x+w]\n",
    "        eyes = cc2.detectMultiScale(roi_gray, scaleFactor=scaleFactor, minNeighbors=20, minSize=(50,50));\n",
    "        for (ex, ey, ew, eh) in eyes:\n",
    "            cv2.rectangle(roi_gray, (ex, ey), (ex + ew, ey + eh), (0, 255, 0), 2)\n",
    "        smile = cc3.detectMultiScale(roi_gray, scaleFactor=scaleFactor, minNeighbors=25, minSize=(120,120));\n",
    "        for (xx, yy, ww, hh) in smile:\n",
    "            cv2.rectangle(roi_gray, (xx, yy), (xx + ww, yy + hh), (0, 0, 255), 2)\n",
    "        #resized_img = cv2.resize(gray_img[y:y+h, x:x+w], (200,200))\n",
    "    return gray_img, faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#13\n",
    "def illumination_normalize(array1d):\n",
    "    image_bgr=[]\n",
    "    image_ycrcb=[]\n",
    "    image_gray=[]\n",
    "    for i in array1d:\n",
    "        image_reshape = i.reshape(100,100)\n",
    "        bgr_image = cv2.cvtColor(image_reshape, cv2.COLOR_GRAY2BGR) # Convert gray to bgr\n",
    "        ycrcb_image = cv2.cvtColor(bgr_image, cv2.COLOR_BGR2YCrCb) # Convert bgr to ycrcb\n",
    "        # separate channels\n",
    "        y, cr, cb = cv2.split(ycrcb_image)\n",
    "\n",
    "        # get background which paper says (gaussian blur using standard deviation 5 pixel for 300x300 size image)\n",
    "        # account for size of input vs 300\n",
    "        sigma = int(5 * 100 / 100)\n",
    "        #print('sigma: ',sigma)\n",
    "        gaussian = cv2.GaussianBlur(y, (0, 0), sigma, sigma)\n",
    "\n",
    "        # subtract background from Y channel\n",
    "        y = (y - gaussian + 100)\n",
    "\n",
    "        # merge channels back\n",
    "        ycrcb = cv2.merge([y, cr, cb])\n",
    "\n",
    "        #convert to BGR\n",
    "        output_bgr = cv2.cvtColor(ycrcb, cv2.COLOR_YCrCb2BGR)\n",
    "        \n",
    "        #convert to grayscale\n",
    "        output_gray = cv2.cvtColor(output_bgr, cv2.COLOR_BGR2GRAY) # 2D\n",
    "        output_gray1d = output_gray.reshape(-1) # 1D\n",
    "        \n",
    "        image_gray.append(output_gray1d)\n",
    "        image_gray_array = np.array(image_gray)\n",
    "        image_bgr.append(bgr_image)\n",
    "        image_bgr_array = np.array(image_bgr)\n",
    "        image_ycrcb.append(ycrcb_image)\n",
    "        image_ycrcb_array = np.array(image_ycrcb)\n",
    "\n",
    "    return image_gray_array, image_bgr_array, image_ycrcb_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#14\n",
    "def dimension_reduction(face_encoding, n=15, m=100):\n",
    "    # Compute covariance matrix, return shape (2622, 2622)\n",
    "    covariance = np.dot(face_encoding.T, face_encoding) / n\n",
    "    print(\"covariance matrix shape (2622, 2622): \", covariance.shape)\n",
    "    total_features = face_encoding.shape[1] # 2622 features\n",
    "    print(\"Calculaing top eigenvalues and corresponding eigenvectors...\")\n",
    "    # Compute eigenval and eigenvec, return shape (1, m) and (2622, m)\n",
    "    eigenvalues, eigenvectors = linalg.eigh(covariance, eigvals=(total_features-m,total_features-1))\n",
    "    print(\"eigenvalues shape (m,): \", eigenvalues.shape)\n",
    "    print(\"eigenvectors shape (2622, m): \", eigenvectors.shape)\n",
    "    print(\"Eigens Computation Done!\")\n",
    "    # Compute eigenfaces, return shape (m, 2622)\n",
    "    eigenfaces = eigenvectors.T\n",
    "    print(\"eigenface shape (m,2622)\", eigenfaces.shape)\n",
    "    # Project zero mean faces into eigen space for training, return shape (15, m)\n",
    "    face_train = np.dot(face_encoding, eigenvectors)\n",
    "    print(\"face_train (15,m): \", face_train.shape)\n",
    "    return eigenvalues, eigenvectors, eigenfaces, face_train, covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#15\n",
    "def findCosineSimilarity(source, test):\n",
    "    a = np.matmul(np.transpose(source), test)\n",
    "    b = np.sum(np.multiply(source, source))\n",
    "    c = np.sum(np.multiply(test, test))\n",
    "    return 1 - (a / (np.sqrt(b) * np.sqrt(c)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#16\n",
    "def vgg_face_recognition(name_array, face_train, eigenvector):\n",
    "    faceCascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml') # load classifier\n",
    "    eye_glassesCascade = cv2.CascadeClassifier('haarcascade_eye_tree_eyeglasses.xml')\n",
    "    \n",
    "    with open('vggface_model.pickle', 'rb') as vggface:\n",
    "        custom_vgg_model = pickle.load(vggface)\n",
    "    \n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    cap.set(3,1280) # set Width\n",
    "    cap.set(4,960) # set Height\n",
    "    while True:\n",
    "        _, frame = cap.read()\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # detect faces\n",
    "        faces = faceCascade.detectMultiScale(\n",
    "            gray,     \n",
    "            scaleFactor=1.2,\n",
    "            minNeighbors=5,     \n",
    "            minSize=(5, 5)\n",
    "        )\n",
    "        for (x,y,w,h) in faces:\n",
    "            cv2.rectangle(frame,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "            roi_color = frame[y:y+h, x:x+w]\n",
    "            roi_gray = gray[y:y+h, x:x+w]\n",
    "            resized_color = cv2.resize(frame[y:y+h,x:x+w], dsize=(224,224), interpolation=cv2.INTER_AREA)\n",
    "            eyes = eye_glassesCascade.detectMultiScale(roi_gray, scaleFactor=1.2, minNeighbors=5, minSize=(5,5))\n",
    "            for (ex, ey, ew, eh) in eyes:\n",
    "                cv2.rectangle(roi_color, (ex, ey), (ex + ew, ey + eh), (0, 255, 0), 2)\n",
    "    #         smile = smileCascade.detectMultiScale(roi_gray, scaleFactor=1.2, minNeighbors=25, minSize=(120,120))\n",
    "    #         for (xx, yy, ww, hh) in smile:\n",
    "    #             cv2.rectangle(roi_color, (xx, yy), (xx + ww, yy + hh), (0, 0, 255), 2)\n",
    "            rgb_face_resize = np.reshape(resized_color, (1,224,224,3))\n",
    "            y_pred = custom_vgg_model.predict(rgb_face_resize) # 1x2622\n",
    "            captured_representation = np.dot(y_pred, eigenvector) # 1x100\n",
    "            \n",
    "            \n",
    "            found=0\n",
    "            min_value=1\n",
    "            for i in range(len(name_array)):\n",
    "                similarity = findCosineSimilarity(face_train[i], captured_representation.T)\n",
    "                if((similarity < 0.1) & (similarity < min_value)):\n",
    "                    min_value = similarity\n",
    "                    name = name_array[i]\n",
    "                    found=1\n",
    "            if (found==1):\n",
    "                #cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "                cv2.putText(frame, name, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "                #cv2.putText(frame, name, (int(x+w), int(y-30)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2)\n",
    "                print(name, min_value)\n",
    "            \n",
    "                    \n",
    "            elif (found==0):\n",
    "                cv2.putText(frame, 'Unknown', (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "                print('Unknown', similarity)\n",
    "                \n",
    "        cv2.imshow('frame',frame)\n",
    "        k = cv2.waitKey(10) & 0xff\n",
    "        if k == 27: # press 'ESC' to quit\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
